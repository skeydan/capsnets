{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### based on https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACDCAYAAACp4J7uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADuZJREFUeJzt3WtsFUUUwPFpwUqLCCIPgyJijFCjiAUF1CIKKCASbdEI\nMRAkBaMUET7Iq5hYDaZRqqRiKUaNVBokPHzERwQVkNQgRKNGIKi0DaRQGqlGo9hK/UA4zozd29s7\ne/e+/r9PZ3K2905ctp7uzJ5Na21tVQAAAIhMeqwnAAAAkMgopgAAABxQTAEAADigmAIAAHBAMQUA\nAOCAYgoAAMABxRQAAIADiikAAAAHFFMAAAAOKKYAAAAcdA74+3h3Teyl+fQ5nMvY8+tcKsX5jAdc\nm8mDazO5tHs+uTMFAADggGIKAADAAcUUAACAA4opAAAABxRTAAAADiimAAAAHFBMAQAAOKCYAgAA\ncBB0004AAMJ25swZiRctWmTkysrKJK6urjZyw4cPj+7EAA13pgAAABxQTAEAADigmAIAAHDAnikA\nQNxoaGgwxkVFRRJXVFR4/tyRI0eMMXum4kNBQYExrqyslHjPnj1GLicnJ5A5RQN3pgAAABxQTAEA\nADhgmQ8po7a2VuJ169YZuWeffVbitLQ0I9fa2ipxdna2kXvmmWckzsvL82WeQKqpr6+XuKSkxMiF\nWtrLzc2VeMSIEf5PDM4GDBhgjP/66y+JDx8+bORY5gMAAEhRFFMAAAAOKKYAAAAcpOn7QQIQ6Jeh\nTWntHxKWuDyXJ0+eNMYrV66U+K233pK4sbHROE6/DkLtmbJzl19+ucRfffWVkevVq1e4046UX+dS\nqTg6n3///bfEY8eONXJffPFFmz/To0cPY/ztt99K3L9/fx9nF1VJfW3aWlpaJF6wYIHEL7/8sufP\nPPbYY8Z41apVEmdkZPg4O2dJeW1GYv369cZ4xowZEk+cONHIffDBB4HMKQLtnk/uTAEAADigmAIA\nAHBAawSl1Ouvv26M9aWciy++WOIDBw4Yx40aNUpi/RFdBEtvT6B3S1bKPJfhLtf17t3b87vs5cGa\nmhqJR48ebeR++OGHELPGOfqynlJKzZ49W2KvZT2llLr33nslXrx4sZHr16+f87xOnDhhjPv27ev8\nmfjPkiVLJA61tDd37lyJy8rKojonBCvOlmadcGcKAADAAcUUAACAA4opAAAAB3G5Z2rDhg3G+Ouv\nv5b4tdde8/37mpqaPHOdO//3n8je29GlSxeJs7KyjNyQIUMkfvvtt41cqD056Lh33nlHYnsvlD0+\n55prrjHGn3/+ucShWhrs3r3bGN92220SHzp0qN254v9eeOEFY6y/Vd6mPxr//PPPS6xfiy4WLVok\nsb2XcsWKFRLrj/IjPE899ZQx1s+fbt68ecZYb3+AxLN161bP3LRp0wKcSXRxZwoAAMABxRQAAICD\nuOmAvnDhQolfeuklI3fmzJnozSgAt99+uzGuqqqSOAaPWyd8l2W7RcVNN90ksd7KQilzSVVfvrOX\nDvR/c0uXLjVyetsEm76MaC8plpeXSzxnzhzPz3CQsF2Wv//+e4n186eUUn/++afE3bp1M3K//PKL\nxPoSfKTsrvUTJkxo87uUUqq0tFTiKC3zJfy1afvyyy8lnjRpkpE7deqUxHr7gzVr1hjHpacn5N/8\nCXtt+kHfmjNy5Egjd+GFF0pcV1dn5DIzM6M7scjRAR0AACCaKKYAAAAcUEwBAAA4iJvWCJs2bZLY\n3iOltxmIdE31lltuMcb6qygitX37donffPNNI6e/ZuSzzz4zcvrjoBs3bjRytE1oX3Z2tjHW973Y\nbQ282hxUVFR4ju39TfqeqS1bthi5UHum8vLy2vxuKPXcc89JrO+RUkqp8847T+J3333XyPmxT0pn\nP56v75OyX3Xhx++MVKO3k9D3SCml1D333COx/hqoBN0jBY3eRshuKaSf3zjeI9Vh/KsFAABwQDEF\nAADgIG6W+Xbs2CGx/ti0UkqNHz9eYvtR6VjKzc2VeObMmUbu7rvvlvjgwYNGTl/2s5cH9Q7MCM/g\nwYM7/DP28t+gQYMkttsr6I/E68tTSimltxaxl2hDdVJPdfv37/fM6e0JxowZ43ncP//8I7G9lBDK\nTz/9JPHOnTs9j8vPzzfGV1xxRdjfgbO+++47z1xBQYHEl156aRDTQUA2b94c6ykEjjtTAAAADiim\nAAAAHFBMAQAAOIibPVNXX311m3GiuPLKK41xcXGxxPfff7/nz9l7cNgz5WbXrl3GWN+vpu9hstsr\nHDp0SOIRI0YYuYaGBont9gd9+vSR+MMPP4xgxrCdPn3aM7d3716Jly9fLvEnn3ziy3dfcsklEtuv\nFUL73n//fWN8/Phxie1WIZMnTw5kTghefX19rKcQOO5MAQAAOKCYAgAAcBA3y3yAHzZs2GCM9c7m\nehsDe7lOz+nLenbObn9QWFgocU5OTgQzTk1PPvmkxLNmzTJyeuuQO+64w8jprQzsNyX4QX9c/9pr\nr/X985Od/YYA3dSpU42xfQ36Tf/3QVd1RBv/wgAAABxQTAEAADhgmc8na9asMcb79u0L6+fsl7zq\nnaGHDRvmPrEU57WUEGqJwc6NHj1a4lWrVhk5lvYiU1dX55lrbm6W2H5JuG7kyJES33fffUbu2LFj\nEq9evTrseQ0fPjzsY/F/+ouibfabBfxQXV0tcXl5uZE7evSoxJs2bTJyPXv29H0uqU5/C8GRI0c8\nj4vkjRWJgDtTAAAADiimAAAAHFBMAQAAOGDPlPp/t9bKykqJS0tLI/qMcP3xxx/GWH8U/Ndff43o\nM1PZ9OnTjXFtba3EjY2NEuud0ZVS6vfff/f8zKefflpi9kj54+GHH5Y4IyMj7J978MEHJe7fv7/E\nnTp1Mo5buXJlWJ936623GuNJkyaFPRecderUKYl37Njh++frvyPtfaT63hx9z45t4cKFxviNN97w\nZ3IQ+nnas2eP53Hjxo0LYjqB484UAACAA4opAAAABymzzLd9+3ZjrLcgWLt2rZEL9VhntOnLH+g4\nvY1BW+Nz7GW+ZcuWSbxt2zYjp7982n6Zsf7yZITvsssuk3jx4sW+f37Xrl3DOm7+/PnGuHPnlPmV\n6JuWlhaJQy2Xh6uqqsoYl5SUSKy/kLwj2DIRfeFudZkwYUKUZxIb3JkCAABwQDEFAADggGIKAADA\nQVJtEDh8+LAxfuSRRyT+9NNPI/rMAQMGSHzRRRd5HldcXGyMu3TpIvG8efOMXKh1/379+nV0iknj\n5MmTEvfu3Tuq32W/0mDz5s0ST5w40ch99NFHEuttM5RSasGCBVGYHVylp3v/najnrrrqqiCmk9Sy\nsrIkHjRokJEL9bvut99+k3jjxo0Sz5kzx8fZnZWZmen7Z8Jk/z/wnMmTJxvjZG0vw50pAAAABxRT\nAAAADhJ+mU/vUF5WVmbkfv75Z4kvuOACI9e9e3eJn3jiCSOnL7XdfPPNEutLfh2hf5etW7duxti+\nJZrMdu3aZYz1FgT2Mtz69esDmZNSSi1dutQYf/zxxxJH+mg2glVRUeGZu/POOyW+4YYbgphOUtPb\nUNjXrX69FBUVGbmGhgaJa2pqfJ/X0KFDJX7xxRd9/3yYvLrf29tj7LcVJAvuTAEAADigmAIAAHBA\nMQUAAOAg4fdMVVdXS6zvkVJKqSlTpkis78dRyvs1I3755ptvJK6trfU87vzzzzfG2dnZUZtTPNDb\nH8ydO9fI9e3bV+Ig90gpZb7x3J5Xa2troHNBx9mvC9Efu7fRziJ67Gvnvffek3jv3r2+f19aWprE\nBQUFRk5/VL9Pnz6+f3eqO3HihDFubm6O0UziA3emAAAAHFBMAQAAOEj4Zb7y8nKJhwwZYuSWL18e\n9HTEjz/+KLF9O1Q3bty4IKYTN7Zu3Sqx3WZgzJgxgc3jwIEDxjg/P19ie176UoL96Dfig72EpC+t\nZ2RkGLmePXsGMqdUZL89QF9eO378uPPnT5s2zRhPnz5d4lRqKxMP7E71TU1NbR6nn6Nkxp0pAAAA\nBxRTAAAADiimAAAAHCT8nil9/0Ms90jZ9JYNth49ekg8f/78IKYTN3JzcyW2Ww7s3LlT4srKSiOn\nt4wYNmyY5+fbbSh2794t8ZYtWyTetm2bcZw+F32PlFLmo/SPP/6453cjdgoLCz1z9qukbrzxxmhP\nB2GYNWuWxPqrX2bPnm0cl57+39/8mZmZ0Z8YPB09elTi/fv3ex6n7wW+6667ojqneMGdKQAAAAcU\nUwAAAA4SfpkvXlx33XXG+ODBg57H6m+tHzVqVNTmFI/05bq8vDwjpy+9zZgxw8jpS285OTmen19X\nV2eMGxsbJQ61lKezl4tTbSk2EZ0+fdozd/311wc4E3hZvXq1MX700Ucl7tSpU9DTQQQaGhokPnbs\nmOdxM2fOlDjU79pkwp0pAAAABxRTAAAADiimAAAAHLBnyic1NTXGuKWlReLu3bsbOd5af5b+KiCl\nzP1O+/bt8/w5O6evydvtFvRcVlaWxPreLaWUWrJkicT2Xi4kNvbjxE59fX2sp4CA6G1vpkyZEsOZ\nxAZ3pgAAABxQTAEAADhIs5dFoizQL4u2qqoqiR966CEj17VrV4lfffVVI/fAAw9Ed2Kh+fWcqu/n\nUm9jUFRU5Hnc2rVrjXF+fr7EvXr18vw5vXv54MGDI5livPHzmeOEvjYHDhxojPVl94yMDCO3bNky\niVesWBHVeXVQ3F6b6DCuzeTS7vnkzhQAAIADiikAAAAHFFMAAAAOaI3QAc3Nzca4pKREYntfxtSp\nUyWO8R6phKHvd3rllVc8jwuVQ2oqLCw0xsXFxRI3NTUZufR0/oYE4C9+qwAAADigmAIAAHBAa4QO\n0LuaK6VUaWmpxEOHDjVy48ePD2ROEeDx6+TB49fJhWszeXBtJhdaIwAAAEQTxRQAAIADiikAAAAH\n7JlKPezLSB7sy0guXJvJg2szubBnCgAAIJoopgAAABwEvcwHAACQVLgzBQAA4IBiCgAAwAHFFAAA\ngAOKKQAAAAcUUwAAAA4opgAAABxQTAEAADigmAIAAHBAMQUAAOCAYgoAAMABxRQAAIADiikAAAAH\nFFMAAAAOKKYAAAAcUEwBAAA4oJgCAABwQDEFAADggGIKAADAAcUUAACAA4opAAAABxRTAAAADiim\nAAAAHFBMAQAAOPgXNIeXh9H25HoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4c51a20b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = mnist.train.images[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, 6, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First conv layer\n",
    "\n",
    "256 filters with a 9x9 kernel\n",
    "\n",
    "output shape will be 20x20 because of no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1/Relu:0' shape=(?, 20, 20, 256) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\", # = none\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second conv layer == Primary capsules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The second layer (PrimaryCapsules) is a convolutional capsule layer with 32 channels of convolutional 8D capsules (i.e. each primary capsule contains 8 convolutional units with a 9 × 9 kernel and a stride of 2)._\n",
    "\n",
    "- 32 primary capsules\n",
    "\n",
    "- Each capsule contains 8 conv units so we have 32x8 = 256 conv units overall\n",
    "\n",
    "- There are 32x6x6 = 1152 8d outputs\n",
    "\n",
    "_In total PrimaryCapsules has [32×6×6] capsule outputs (each output is an 8D vector) and each capsule in the\n",
    "[6×6] grid is sharing their weights with each other._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps1_n_maps = 32 # primary capsules\n",
    "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsule outputs\n",
    "caps1_n_dims = 8  # conv units per capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2/Relu:0' shape=(?, 6, 6, 256) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape to (batch size, 6×6×32, 8) which is equivalent in this case to (batch size, 6×6×32, 8) (because primary capsules are fully connected to digit capsules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_raw:0' shape=(?, 1152, 8) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "caps1_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Squash\n",
    "\n",
    "_We therefore use a non-linear \"squashing\" function to ensure that short vectors get shrunk to almost zero length and long vectors get shrunk to a length slightly below 1._ \n",
    "\n",
    "$\\operatorname{squash}(\\mathbf{s}) = \\dfrac{\\|\\mathbf{s}\\|^2}{1 + \\|\\mathbf{s}\\|^2} \\dfrac{\\mathbf{s}}{\\|\\mathbf{s}\\|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-e16d4cdcedf6>:4: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output/mul:0' shape=(?, 1152, 8) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "caps1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps2_n_caps = 10\n",
    "caps2_n_dims = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Compute the Predicted Output Vectors\n",
    "\n",
    "The transformation matrix $W_{ij}$ must transform from 8d to 16d and so, be of shape 16x8.\n",
    "\n",
    "The code computes all predicted vectors for all combinations (i,j) at once, like this - but with one additional dimension, the batch dimension:\n",
    "\n",
    "$\n",
    "\\pmatrix{\n",
    "  \\mathbf{W}_{1,1} & \\mathbf{W}_{1,2} & \\cdots & \\mathbf{W}_{1,10} \\\\\n",
    "  \\mathbf{W}_{2,1} & \\mathbf{W}_{2,2} & \\cdots & \\mathbf{W}_{2,10} \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\mathbf{W}_{1152,1} & \\mathbf{W}_{1152,2} & \\cdots & \\mathbf{W}_{1152,10}\n",
    "} \\times\n",
    "\\pmatrix{\n",
    "  \\mathbf{u}_1 & \\mathbf{u}_1 & \\cdots & \\mathbf{u}_1 \\\\\n",
    "  \\mathbf{u}_2 & \\mathbf{u}_2 & \\cdots & \\mathbf{u}_2 \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\mathbf{u}_{1152} & \\mathbf{u}_{1152} & \\cdots & \\mathbf{u}_{1152}\n",
    "}\n",
    "=\n",
    "\\pmatrix{\n",
    "\\hat{\\mathbf{u}}_{1|1} & \\hat{\\mathbf{u}}_{2|1} & \\cdots & \\hat{\\mathbf{u}}_{10|1} \\\\\n",
    "\\hat{\\mathbf{u}}_{1|2} & \\hat{\\mathbf{u}}_{2|2} & \\cdots & \\hat{\\mathbf{u}}_{10|2} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\hat{\\mathbf{u}}_{1|1152} & \\hat{\\mathbf{u}}_{2|1152} & \\cdots & \\hat{\\mathbf{u}}_{10|1152}\n",
    "}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'W:0' shape=(1, 1152, 10, 16, 8) dtype=float32_ref>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_sigma = 0.1\n",
    "\n",
    "#  this variable of shape (1, 1152, 10, 16, 8) will hold all the transformation matrices\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'W_tiled:0' shape=(?, 1152, 10, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "# tile to work on batch\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "W_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output_expanded:0' shape=(?, 1152, 8, 1) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output_tile:0' shape=(?, 1152, 1, 8, 1) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand once per digit class\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output_tiled:0' shape=(?, 1152, 10, 8, 1) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and tile\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "caps1_output_tiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compute predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing by agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'raw_weights:0' shape=(?, 1152, 10, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw routing weights\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "raw_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compute softmax\n",
    "\n",
    "$\\mathbf{c}_{i} = \\operatorname{softmax}(\\mathbf{b}_i)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-d970183d1805>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compute the weighted sum of all the predicted output vectors for each second-layer capsule,\n",
    "\n",
    "$\\mathbf{s}_j = \\sum\\limits_{i}{c_{i,j}\\hat{\\mathbf{u}}_{j|i}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To perform elementwise matrix multiplication (also called the Hadamard product, noted $\\circ$), we use the `tf.multiply()` function. It requires `routing_weights` and `caps2_predicted` to have the same rank, which is why we added two extra dimensions of size 1 to `routing_weights`, earlier.\n",
    "* The shape of `routing_weights` is (_batch size_, 1152, 10, 1, 1) while the shape of `caps2_predicted` is (_batch size_, 1152, 10, 16, 1).  Since they don't match on the fourth dimension (1 _vs_ 16), `tf.multiply()` automatically _broadcasts_ the `routing_weights` 16 times along that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### squash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
